{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_best_model = True\n",
    "compute_best_model = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "from datetime import datetime as dt\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "# from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "# import tensorflow as tf\n",
    "# tf.get_logger().setLevel('INFO')\n",
    "# tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "# import keras\n",
    "# from keras.models import Model\n",
    "# from keras.layers import Input, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'curated-data/CorrelationData.csv' does not exist: b'curated-data/CorrelationData.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-17a811a53747>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'curated-data/CorrelationData.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    683\u001b[0m         )\n\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1135\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1136\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1917\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'curated-data/CorrelationData.csv' does not exist: b'curated-data/CorrelationData.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('CorrelationData.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NASA</th>\n",
       "      <th>TA</th>\n",
       "      <th>EXT</th>\n",
       "      <th>AGR</th>\n",
       "      <th>CS</th>\n",
       "      <th>NT</th>\n",
       "      <th>OP</th>\n",
       "      <th>AV</th>\n",
       "      <th>EM</th>\n",
       "      <th>Task</th>\n",
       "      <th>...</th>\n",
       "      <th>T_1</th>\n",
       "      <th>T_2</th>\n",
       "      <th>T_3</th>\n",
       "      <th>T_4</th>\n",
       "      <th>T_5</th>\n",
       "      <th>DS_1</th>\n",
       "      <th>DS_2</th>\n",
       "      <th>DS_3</th>\n",
       "      <th>DS_4</th>\n",
       "      <th>DS_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>28</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>35</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>21</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   NASA  TA  EXT  AGR  CS  NT  OP  AV  EM  Task  ...  T_1  T_2  T_3  T_4  T_5  \\\n",
       "0    18  28    6    4  10   3   8  13  12    35  ...    0    0    0    0    1   \n",
       "1    20  34    5    6  10   5   5  15  18    28  ...    0    0    0    0    1   \n",
       "2    19  22    4    7  10   2   9  14  10    24  ...    0    0    1    0    0   \n",
       "3    18  35    4    9  10   3   6  15  21    32  ...    0    1    0    0    0   \n",
       "4    15  24   10   10   6   3   9  19  10    31  ...    0    0    0    0    1   \n",
       "\n",
       "   DS_1  DS_2  DS_3  DS_4  DS_5  \n",
       "0     0     0     1     0     0  \n",
       "1     0     0     1     0     0  \n",
       "2     0     0     1     0     0  \n",
       "3     0     0     0     1     0  \n",
       "4     0     0     1     0     0  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_cols = ['Rank', 'RS', 'WH', 'BR', 'NP', 'AP', 'AR', 'DWH', 'T', 'DS']\n",
    "df=pd.get_dummies(df, columns=cat_cols)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['NASA', 'TA', 'EXT', 'AGR', 'CS', 'NT', 'OP', 'AV', 'EM', 'Task', 'H',\n",
       "       'TWR', 'SR', 'DWR', 'Rank_Assistant Professor',\n",
       "       'Rank_Associate Professor', 'Rank_Professor', 'RS_1', 'RS_2', 'WH_1',\n",
       "       'WH_2', 'WH_3', 'WH_4', 'BR_1', 'BR_2', 'BR_3', 'BR_4', 'NP_1', 'NP_2',\n",
       "       'NP_3', 'NP_4', 'NP_5', 'AP_1', 'AP_2', 'AP_3', 'AP_4', 'AR_1', 'AR_2',\n",
       "       'AR_3', 'AR_4', 'AR_5', 'DWH_1', 'DWH_2', 'DWH_3', 'DWH_4', 'DWH_5',\n",
       "       'T_1', 'T_2', 'T_3', 'T_4', 'T_5', 'DS_1', 'DS_2', 'DS_3', 'DS_4',\n",
       "       'DS_5'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 147 entries, 0 to 146\n",
      "Data columns (total 56 columns):\n",
      "NASA                        147 non-null int64\n",
      "TA                          147 non-null int64\n",
      "EXT                         147 non-null int64\n",
      "AGR                         147 non-null int64\n",
      "CS                          147 non-null int64\n",
      "NT                          147 non-null int64\n",
      "OP                          147 non-null int64\n",
      "AV                          147 non-null int64\n",
      "EM                          147 non-null int64\n",
      "Task                        147 non-null int64\n",
      "H                           147 non-null int64\n",
      "TWR                         147 non-null int64\n",
      "SR                          147 non-null int64\n",
      "DWR                         147 non-null int64\n",
      "Rank_Assistant Professor    147 non-null uint8\n",
      "Rank_Associate Professor    147 non-null uint8\n",
      "Rank_Professor              147 non-null uint8\n",
      "RS_1                        147 non-null uint8\n",
      "RS_2                        147 non-null uint8\n",
      "WH_1                        147 non-null uint8\n",
      "WH_2                        147 non-null uint8\n",
      "WH_3                        147 non-null uint8\n",
      "WH_4                        147 non-null uint8\n",
      "BR_1                        147 non-null uint8\n",
      "BR_2                        147 non-null uint8\n",
      "BR_3                        147 non-null uint8\n",
      "BR_4                        147 non-null uint8\n",
      "NP_1                        147 non-null uint8\n",
      "NP_2                        147 non-null uint8\n",
      "NP_3                        147 non-null uint8\n",
      "NP_4                        147 non-null uint8\n",
      "NP_5                        147 non-null uint8\n",
      "AP_1                        147 non-null uint8\n",
      "AP_2                        147 non-null uint8\n",
      "AP_3                        147 non-null uint8\n",
      "AP_4                        147 non-null uint8\n",
      "AR_1                        147 non-null uint8\n",
      "AR_2                        147 non-null uint8\n",
      "AR_3                        147 non-null uint8\n",
      "AR_4                        147 non-null uint8\n",
      "AR_5                        147 non-null uint8\n",
      "DWH_1                       147 non-null uint8\n",
      "DWH_2                       147 non-null uint8\n",
      "DWH_3                       147 non-null uint8\n",
      "DWH_4                       147 non-null uint8\n",
      "DWH_5                       147 non-null uint8\n",
      "T_1                         147 non-null uint8\n",
      "T_2                         147 non-null uint8\n",
      "T_3                         147 non-null uint8\n",
      "T_4                         147 non-null uint8\n",
      "T_5                         147 non-null uint8\n",
      "DS_1                        147 non-null uint8\n",
      "DS_2                        147 non-null uint8\n",
      "DS_3                        147 non-null uint8\n",
      "DS_4                        147 non-null uint8\n",
      "DS_5                        147 non-null uint8\n",
      "dtypes: int64(14), uint8(42)\n",
      "memory usage: 22.2 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': [True, False],\n",
      " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None],\n",
      " 'max_features': ['auto', 'sqrt'],\n",
      " 'min_samples_leaf': [1, 2, 4],\n",
      " 'min_samples_split': [2, 5, 10],\n",
      " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_splitted_data(df, feature_list, predict_col, random=False):\n",
    "    if random:\n",
    "        msk = np.random.rand(len(df)) < 0.75\n",
    "        train_df = df[msk].copy()\n",
    "        test_df = df[~msk].copy()\n",
    "    else:\n",
    "        split = np.int32(0.8 * len(df))\n",
    "\n",
    "        train_df = df[:split].copy()\n",
    "        test_df = df[split:].copy()\n",
    "        \n",
    "#     print(len(train_df))\n",
    "#     print(len(test_df))\n",
    "\n",
    "    X_train = train_df[feature_list]\n",
    "    y_train = np.int32(train_df[[predict_col]])\n",
    "\n",
    "    X_test = test_df[feature_list]\n",
    "    y_test = np.int32(test_df[predict_col])\n",
    "\n",
    "#     y_test_state = test_df[['State', predict_col]]\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time():\n",
    "    return dt.today().strftime('%Y_%m_%d_%H_%M_%S')\n",
    "\n",
    "    \n",
    "def compute_best_param():\n",
    "    # Use the random grid to search for best hyperparameters\n",
    "    # First create the base model to tune\n",
    "    rf = RandomForestRegressor()\n",
    "    \n",
    "    # Random search of parameters, using 5 fold cross validation, \n",
    "    # Search across 100 different combinations, and use all available cores\n",
    "    rf_random = RandomizedSearchCV(estimator = rf, \n",
    "                                   param_distributions = random_grid, \n",
    "                                   n_iter = 20, \n",
    "                                   cv = 5, \n",
    "                                   verbose = 2, \n",
    "                                   random_state = 42, \n",
    "                                   n_jobs = -1) \n",
    "    \n",
    "    # Fit the random search model\n",
    "    rf_random.fit(X_train, y_train)\n",
    "    \n",
    "    return str(rf_random.best_params_)\n",
    "\n",
    "def get_model(ml_alg):\n",
    "    if ml_alg=='random_forest':\n",
    "        if not run_best_model:\n",
    "            model = RandomForestClassifier(n_estimators = 200,\n",
    "                                   max_features = 'auto',\n",
    "                                   bootstrap = True)\n",
    "        else:\n",
    "            model = RandomForestClassifier( n_estimators = 1600, \n",
    "                                            min_samples_split = 10, \n",
    "                                            min_samples_leaf = 2, \n",
    "                                            max_features = 'auto', \n",
    "                                            max_depth = None, \n",
    "                                            bootstrap = True)\n",
    "    elif ml_alg=='xgboost':\n",
    "        model =  XGBClassifier()\n",
    "    elif ml_alg=='svm':\n",
    "        model =  svm.SVC(kernel='linear')\n",
    "    elif ml_alg=='linear_svm':\n",
    "        model =  LinearSVC(random_state=0, tol=1e-5)\n",
    "    elif ml_alg=='logistic':\n",
    "        model =  LogisticRegression()\n",
    "        \n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def conduct_modeling(ml_alg):\n",
    "    print(ml_alg + '...', end=' ')\n",
    "    \n",
    "    model = get_model(ml_alg)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    result_df = pd.DataFrame({\n",
    "        'actual': y_test, \n",
    "        'prediction': y_pred,\n",
    "    })\n",
    "\n",
    "#     result_df.to_csv('modeling-result/result_df.csv', index=False)\n",
    "    result_df.to_csv('modeling-result/' + ml_alg + '_' + get_time() + '_df.csv', index=False)\n",
    "\n",
    "    # generate evaluation metrics\n",
    "    print(metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "    if ml_alg=='random_forest':\n",
    "        f = open('modeling-result/random_forest' + '_' + get_time() + '.txt', \"w\")\n",
    "        fi = pd.DataFrame({'feature': feature_list,\n",
    "                           'importance': model.feature_importances_}).sort_values('importance', ascending = False)\n",
    "        f.write(str(fi))\n",
    "        f.write('\\n\\n\\n')\n",
    "        \n",
    "        ################################################################################################################################\n",
    "        if compute_best_model:\n",
    "            f.write(compute_best_param())\n",
    "        ################################################################################################################################\n",
    "        \n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_forest... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shailazaman/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:55: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3225806451612903\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   29.0s finished\n",
      "/Users/shailazaman/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/Users/shailazaman/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:715: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic... 0.22580645161290322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shailazaman/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/shailazaman/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shailazaman/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "predict_col = 'SR'\n",
    "feature_list = list(df.columns)\n",
    "feature_list.remove(predict_col)\n",
    "\n",
    "\n",
    "################################################################################################################################\n",
    "# X_train, y_train, X_test, y_test, y_test_state = get_splitted_data(state_df.sort_values('Date'), feature_list, predict_col)\n",
    "X_train, y_train, X_test, y_test = get_splitted_data(df, feature_list, predict_col, random=True)\n",
    "################################################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################################################################################################################################\n",
    "# draw_correlation_plot(X_train.copy())\n",
    "# draw_pair_plot(X_train.copy())\n",
    "################################################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################################################################################################################################\n",
    "# # ml_alg_list = ['random_forest', 'xgboost', 'svm', 'linear_svm']\n",
    "ml_alg_list = ['random_forest', 'logistic']\n",
    "\n",
    "# # map(lambda ml_alg: conduct_modeling(ml_alg), ml_alg_list)\n",
    "for ml_alg in ml_alg_list:\n",
    "    conduct_modeling(ml_alg)\n",
    "################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
