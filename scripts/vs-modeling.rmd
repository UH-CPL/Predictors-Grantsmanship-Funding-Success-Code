---
title: "Logistic Regression"
# title: "Ordinal Logistic Regression or Proportional Odds Logistic Regression"
# title: "Random Forest for predicting the Success Rate Levels Successful-Unsuccessful"
output:
  pdf_document: default
  html_document:
    df_print: paged
---
\newpage
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(ggplot2)
library(GGally)
library(reshape2)
library(plyr)
library(nnet)
library(MASS)
library(caret)
library(mlbench)
library(rms)
require(tidyr)
library(superml)
library(randomForest)
library(aod)
library(pROC)
library(interplot)
library(sjPlot)
library(grid)
library(gridExtra)
library(ggpubr)
library(freqtables)
# require(dplyr)
# install.packages("aod")
# knitr::opts_chunk$set(echo = TRUE)

#######----Source----------#######

####https://www.youtube.com/watch?v=Z5WKQr4H4Xk
####https://www.youtube.com/watch?v=qkivJzjyHoA
####https://www.analyticsvidhya.com/blog/2016/02/multinomial-ordinal-logistic-regression/
####https://www.youtube.com/watch?v=zE7pVAalmfk&feature=youtu.be&t=424
####http://www.sthda.com/english/articles/38-regression-model-validation/157-cross-validation-essentials-in-r/
# http://www.sthda.com/english/articles/24-ggpubr-publication-ready-plots/81-ggplot2-easy-way-to-mix-multiple-graphs-on-the-same-page/
# DWH = Workload a week before proposal deadline

# Deviance is a measure of goodness of fit of a model. Higher numbers always indicates bad fit.
# Akaike information criterion (AIC) (Akaike, 1974) is a fined technique based on in-sample fit to estimate the likelihood of a model to predict/estimate the future values. A good model is the one that has minimum AIC among all the other models. ... A lower AIC or BIC value indicates a better fit.



# Forward selection, which starts with no predictors in the model, iteratively adds the most contributive predictors, and stops when the improvement is no longer statistically significant.
# 
# Backward selection (or backward elimination), which starts with all predictors in the model (full model), iteratively removes the least contributive predictors, and stops when you have a model where all predictors are statistically significant.
# 
# Stepwise selection (or sequential replacement), which is a combination of forward and backward selections. You start with no predictors, then sequentially add the most contributive predictors (like forward selection). After adding each new variable, remove any variables that no longer provide an improvement in the model fit (like backward selection).
```



```{r, echo=FALSE}
root_dir <- getwd()
project_directory <- dirname(root_dir)
data_dir <- file.path(project_directory, 'raw-data')
curated_data_dir <- file.path(project_directory, 'curated-data')
plot_dir <- file.path(project_directory, 'Plots')
# data_file_name <- 'KeyData.csv'
data_file_name <- 'KeyData_399.csv'
# data_file_name_std <- 'StandardPart.csv'


Data <-
  read.csv(file.path(curated_data_dir, data_file_name),
           stringsAsFactors = FALSE)
Data <- Data[complete.cases(Data),]

Data <- Data %>% dplyr::rename(FA = "Funding_Agency")
count(Data$SR)
Data <- Data %>%
  mutate(SR = recode(SR, "1" = 0, "2" = 0, "3" = 1, "4" = 1, "5" = 1, "6" = 1, "7"= 1))

count(Data$SR)

```



<!-- ```{r,echo=FALSE, warning=FALSE} -->
<!-- success_rate <- ggplot(Data, aes(x = SR)) + -->
<!--   geom_histogram(binwidth = .5, stat = "count") + theme_minimal() + -->
<!--   ylim(0, 200) + -->
<!--   ylab("Count") + xlab("Success rate") + scale_x_discrete( -->
<!--     limits = c("1", "2", "3", "4", "5", "6", "7"), -->
<!--     labels = c("< 10%", -->
<!--                "10-20%", -->
<!--                "20-30%", -->
<!--                "30-50%", -->
<!--                "50-75%", -->
<!--                "75-90%", -->
<!--                "> 90%") -->
<!--   ) + ggtitle("Proposals success rate") + theme(plot.title = element_text(hjust = 0.5)) -->
<!-- print(success_rate) -->


<!-- # success_rate <- ggplot(Data, aes(x = SR)) + -->
<!-- #   geom_histogram(binwidth = .5, stat = "count") + theme_minimal() + -->
<!-- #   ylim(0, 180) + -->
<!-- #   ylab("Count") + xlab("Success rate") + scale_x_discrete( -->
<!-- #     limits = c("1", "2", "3"), -->
<!-- #     labels = c("10-30%", -->
<!-- #                "30-50%", -->
<!-- #                "50-100%") -->
<!-- #   ) + ggtitle("Proposals success rate") + theme(plot.title = element_text(hjust = 0.5)) -->
<!-- # print(success_rate) -->
<!-- ``` -->




```{r, echo=FALSE}
Data$SR <- as.factor(Data$SR)
lm_DF <- as.data.frame((Data[, 2:25]))


lm_DF$Rank <- as.factor(Data$Rank)
lm_DF$RS <- as.factor(lm_DF$RS)
lm_DF$WH <- as.factor(lm_DF$WH)
lm_DF$NP <- as.factor(lm_DF$NP)
lm_DF$BR <- as.factor(lm_DF$BR)
lm_DF$DWH <- as.factor(lm_DF$DWH)
lm_DF$FA <- as.factor(lm_DF$FA)
lm_DF$T <- as.factor(lm_DF$T)
lm_DF$DS <- as.factor(lm_DF$DS)
lm_DF$AR <- as.factor(lm_DF$AR)


lbl <- LabelEncoder$new()
lbl$fit(lm_DF$Rank)
lm_DF$Rank <- lbl$fit_transform(lm_DF$Rank)


lm_DF <- lm_DF %>%
  mutate(Rank = recode(Rank, "0" = 1, "1" = 2, "2" = 3))
lm_DF$Rank <- as.factor(lm_DF$Rank)

lm_DF <- lm_DF %>% dplyr::rename(TS = "T",  FR= "Rank", BF = "BR", E = "EXT", PR = "AR")

```





\newpage
## Null Model
```{r, echo=FALSE}
NullModel<-glm(SR~1,data = lm_DF,family="binomial")
summary(NullModel)

```


\newpage
## Logistic Regression: Full MOdel
```{r, echo=FALSE}
# FullModel <- glm(SR ~ Rank+NASA+TA+EXT+AGR+CS+NT+OP+AV+EM+Task+H+RS+WH+TWR+BR+NP+FA+AP+AR+DWH+DWR+T+DS, data = lm_DF, family = "binomial")
FullModel <- glm(SR ~ ., data = lm_DF, family = "binomial")

summary(FullModel)
```
\newpage
## Backward Elimination Model selection
```{r, echo=FALSE}
BEmodel<-stepAIC(FullModel, direction="backward",trace=FALSE)
BEmodel$anova
```

\newpage
## Backward Elimination Model
```{r, echo=FALSE}
# BEmodel<-stepAIC(FullModel, direction="backward",trace=FALSE)
# BEmodel$anova
summary(BEmodel)
```

```{r, echo=FALSE}
dummy_df <- data.frame(x = c(0, 100, 0, 100), 
                       y = c(100, 0, 0, 100), 
                       group=c('a', 'a', 'b', 'b'))

draw_dummy_plot <- function(plot_title) {
  dummy_plot <- ggplot(dummy_df, aes(x=x, y=y, group=group)) + 
    geom_line() +
    theme_minimal() +
    theme(
      plot.title = element_text(hjust = 0.5, size = 10, face = "bold"),
      axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()) + labs(title =  plot_title)
    
  return(dummy_plot)
  dummy_plot
}

```



```{r, echo=FALSE, warning=FALSE, message=FALSE}
model_plot <- function(item, modified, title_) {
  if (item == "NP" | item == "H" | item == "FR") {
    y_title = expression(paste(italic("P")))
    y_text = element_text(face = "bold")
  } else{
    y_title = ""
    y_text = element_blank()
  }
  
  if (item == "NP" | item == "FA"| item == "TS" | item == "FR" | item == "RS" | item == "DS" | item == "BF" | item == "PR"){
    plt = plot_model(BEmodel, type = "pred", terms = item) +
    theme(
      plot.title = element_text(hjust = 0.5, size = 10, face = "bold"),
      panel.grid = element_blank(),
      axis.title = element_text(face = "bold"),
      axis.text.x = element_text(
        face = "bold",
        size = 8,
        angle = 30,
        hjust = 1
      ),
      axis.text.y = element_text(face = "bold")
    ) +
    labs(y = y_title, x = "", title = title_) + scale_y_continuous(
      limits = c(0.0, 1),
      breaks = c(0.0, 0.25, 0.50, 0.75, 1),
      labels = c(
        "0.00" = "0%",
        "0.25" = "25%",
        "0.50" = "50%",
        "0.75" = "75%",
        "1" = "100%"
      )
    ) + theme(axis.text.y = y_text, axis.ticks.y = element_blank()) + scale_x_discrete(limits = modified)
  return(plt)
  } else {
    plt = plot_model(BEmodel, type = "pred", terms = item) +
    theme(
      plot.title = element_text(hjust = 0.5, size = 10, face = "bold"),
      panel.grid = element_blank(),
      axis.title = element_text(face = "bold"),
      axis.text.x = element_text(
        face = "bold",
        size = 8,
        angle = 30,
        hjust = 1
      ),
      axis.text.y = element_text(face = "bold")
    ) +
    labs(y = y_title, x = "", title = title_) + scale_y_continuous(
      limits = c(0.0, 1),
      breaks = c(0.0, 0.25, 0.50, 0.75, 1),
      labels = c(
        "0.00" = "0%",
        "0.25" = "25%",
        "0.50" = "50%",
        "0.75" = "75%",
        "1" = "100%"
      )
    ) + theme(axis.text.y = y_text, axis.ticks.y = element_blank())
  return(plt)
  }
  
}
```


```{r, echo=FALSE}
np_actual = c("1" = "NP1", "2" = "NP2", "3"="NP3")
fa_actual = c("1" = "NSF", "2" = "NIH", "3" = "DOE", "4" = "DOD", "5" = "NASA", "6" = "OTHER")
TS_actual = c("1" = "TS1", "2" = "TS2")
DS_actual = c("1" = "DS1", "2" = "DS2")
BF_actual = c("1" = "BF1", "2" = "BF2")
PR_actual = c("1" = "PR1", "2" = "PR2", "3" = "PR3", "4" = "PR4", "5" = "PR5")
RS_actual = c("1" = "RS1", "2" = "RS2")
FR_actual = c("1" = "FR1", "2" = "FR2", "3" = "FR3")
H_actual = c("0" = "0", "50" = "50", "100" = "100", "150" ="150", "200" = "200")

modified_ticx = list(np_actual, fa_actual, TS_actual, H_actual)
```

## SR 20
```{r, echo=FALSE}
plot_list <- list()
plot_item <- c("NP", "FA", "TS", "H")
title <- c("Number of Proposals", "Funding Agency", "Time of Submission", "h-index")



for (item in 1:length(plot_item)){
  plot = model_plot(plot_item[item], modified_ticx[[item]], title[item])
  plot_list[[length(plot_list) + 1]] <- plot
}




plot_up <- ggarrange(
    plot_list[[1]],
    plot_list[[2]],
    plot_list[[3]], nrow = 1, ncol = 3, labels = c("A", "", ""))
dummy_plot <- draw_dummy_plot("")

plot_down <- ggarrange(plot_list[[4]],
    dummy_plot,
    labels = c("B", "C"),
    ncol = 2,
    nrow = 1)

final_plot <- ggarrange(plot_up, plot_down, ncol = 1,
    nrow = 2
  ) + annotation_custom(grid.polygon(
    c(0, 0.5, 1, 0.507, 0.507),
    c(0.5, 0.5, 0.5, 0, 0.5),
    id = c(1, 1, 1, 2, 2),
    gp = gpar(lwd = 1.5)
  ))



final_plot

# final_plot<-ggarrange(first_row_A, Second_row_B, nrow = 2)
# final_plot

filename <- "SR_prediction_20.pdf"
# filename <- "SR_prediction_20.jpg"
full_path <- file.path(plot_dir, filename)
ggsave(
  full_path,
  final_plot,
  width = 8.5,
  height = 5.5,
  units = "in"
)
```

## SR 30
```{r, echo=FALSE}
plot_list <- list()
plot_item <- c("NP", "FA", "FR", "RS", "TA", "DS")
title <- c("Number of Proposals", "Funding Agency", "Faculty Rank", "Research Style", "Trait Anxiety", "Deadline Stress")
modified_ticx = list(np_actual, fa_actual, FR_actual, RS_actual, H_actual , DS_actual)

for (item in 1:length(plot_item)){
  plot = model_plot(plot_item[item], modified_ticx[[item]], title[item])
  plot_list[[length(plot_list) + 1]] <- plot
}




plot_up <- ggarrange(
    plot_list[[1]],
    plot_list[[2]], nrow = 1, ncol = 2, labels = c("A", ""))

plot_down <- ggarrange(plot_list[[3]],
    plot_list[[4]], plot_list[[5]], plot_list[[6]],
    labels = c("B", "", "C", ""),
    ncol = 4,
    nrow = 1)

final_plot <- ggarrange(plot_up, plot_down, ncol = 1,
    nrow = 2
  ) + annotation_custom(grid.polygon(
    c(0, 0.5, 1, 0.507, 0.507),
    c(0.5, 0.5, 0.5, 0, 0.5),
    id = c(1, 1, 1, 2, 2),
    gp = gpar(lwd = 1.5)
  ))


final_plot


filename <- "SR_prediction_30.pdf"
# filename <- "SR_prediction_30.jpg"
full_path <- file.path(plot_dir, filename)
ggsave(
  full_path,
  final_plot,
  width = 8.5,
  height = 5.5,
  units = "in"
)
```


## SR 50
```{r, echo=FALSE}
plot_list <- list()
plot_item <- c("NP", "FA", "BF","PR", "H", "E")
title <- c("Number of Proposals", "Funding Agency", "Break Frequency", "Pilot Research", "h-index", "Extraversion")
modified_ticx = list(np_actual, fa_actual, BR_actual, PR_actual, H_actual, H_actual)


for (item in 1:length(plot_item)){
  plot = model_plot(plot_item[item], modified_ticx[[item]], title[item])
  plot_list[[length(plot_list) + 1]] <- plot
}
 

plot_up <- ggarrange(
    plot_list[[1]],
    plot_list[[2]],
    plot_list[[3]],
    plot_list[[4]], nrow = 1, ncol = 4, labels = c("A", "", "", ""))

plot_down <- ggarrange(plot_list[[5]], plot_list[[6]],
    labels = c("B", "C"),
    ncol = 2,
    nrow = 1)

final_plot <- ggarrange(plot_up, plot_down, ncol = 1,
    nrow = 2
  ) + annotation_custom(grid.polygon(
    c(0, 0.5, 1, 0.507, 0.507),
    c(0.5, 0.5, 0.5, 0, 0.5),
    id = c(1, 1, 1, 2, 2),
    gp = gpar(lwd = 1.5)
  ))

final_plot


filename <- "SR_prediction_50.pdf"
# filename <- "SR_prediction_50.jpg"
full_path <- file.path(plot_dir, filename)
ggsave(
  full_path,
  final_plot,
  width = 8.5,
  height = 5.5,
  units = "in"
)
```





## Function for new plot
```{r, echo=FALSE}
model_plot_new <- function(item, modified, title_) {
  if (item == "NP" | item == "H" | item == "FR") {
    y_title = expression(paste(italic("P")))
    y_text = element_text(face = "bold")
  } else{
    y_title = ""
    y_text = element_blank()
  }
  
  if (item == "NP" | item == "FA"| item == "TS" | item == "FR" | item == "RS" | item == "DS" | item == "BF" | item == "PR"){
    plt = plot_model(BEmodel, type = "pred", terms = item) +
    theme(
      plot.title = element_text(hjust = 0.5, size = 10, face = "bold"),
      panel.grid = element_blank(),
      axis.title = element_text(face = "bold"),
      axis.text.x = element_text(
        face = "bold",
        size = 8,
        angle = 30,
        hjust = 1
      ),
      axis.text.y = element_text(face = "bold")
    ) +
    labs(y = y_title, x = "", title = title_) + scale_y_continuous(
      limits = c(0.0, 1),
      breaks = c(0.0, 0.25, 0.50, 0.75, 1),
      labels = c(
        "0.00" = "0%",
        "0.25" = "25%",
        "0.50" = "50%",
        "0.75" = "75%",
        "1" = "100%"
      )
    ) + theme(axis.text.y = y_text, axis.ticks.y = element_blank()) + scale_x_discrete(limits = modified)
  return(plt)
  }
}
```


## Plot in new design
```{r, echo=FALSE}
plot_list <- list()
plot_item <- c("NP", "FA", "TS")
title <-
  c("Number of Proposals", "Funding Agency", "Time of Submission")
modified_ticx = list(np_actual, fa_actual, TS_actual, H_actual)


for (item in 1:length(plot_item)) {
  plot = model_plot(plot_item[item], modified_ticx[[item]], title[item])
  plot_list[[length(plot_list) + 1]] <- plot
}



dummy_plot_BF <- draw_dummy_plot("Break Frequency")
dummy_plot_PR <- draw_dummy_plot("Pilot Research")






```


```{r, echo=FALSE}
# p <- sjPlot::plot_model(BEmodel, type = "pred", grid = FALSE)
# lapply(p, function(i) i + scale_y_continuous(limits = c(0.2, 1), breaks = c(0.20, 0.40, 0.60, 0.80, 1), labels=c("0.20" = "20%",
#                               "0.40" = "40%", "0.60" = "60%", "0.80" = "80%", "1" = "100%")))
plot_model(BEmodel, type = "pred")
```






\newpage
## Comparing Models
```{r, echo=FALSE}
anova(NullModel,BEmodel,FullModel,test="LRT")
```


\newpage
## Forward Selection  
```{r, echo=FALSE}
FSmodel<-stepAIC(NullModel,scope=list(lower=formula(NullModel),upper=formula(FullModel)),direction="forward",trace = FALSE)
FSmodel$anova
```

\newpage
## Forward Selection model
```{r, echo=FALSE}
FSmodel <- glm(SR ~ NP + DS + H + RS + FA + TA + Rank, data = lm_DF, family = "binomial")

summary(FSmodel)
```
\newpage
## Comparing Models
```{r, echo=FALSE}
anova(NullModel,BEmodel,FSmodel,FullModel,test="LRT")
```


\newpage
## Step_wise method
```{r, echo=FALSE}
SWmodel<-stepAIC(NullModel,scope=list(lower=formula(NullModel),upper=formula(FullModel)),direction="both",trace = FALSE)
SWmodel$anova
summary(SWmodel)
```



\newpage
## Comparing models
```{r, echo=FALSE}
anova(NullModel,BEmodel,FSmodel,SWmodel,FullModel,test="LRT")
```



<!-- \newpage -->
<!-- ## Model with NP1 as reference -->
```{r, echo=FALSE, warning=FALSE}
# # lm_DF$FA <- relevel(lm_DF$FA, ref = 6)
# base_model = polr(SR ~ FA + H + NP + AGR + TA + RS + DWH + DS, data = lm_DF, Hess = TRUE)
# # base_model=lrm(SR ~ H + NP + AGR, data = lm_DF)
# summary(base_model)
# 
# ctable <- coef(summary(base_model))
# p <- pnorm(abs(ctable[, "t value"]), lower.tail = FALSE) * 2
# ctable <- cbind(ctable, "p value" = round(p, 4))
# ctable
```

```{r, echo=FALSE, warning=FALSE}
# \newpage
## Model with NP1 as reference and kfold cross validation

# set.seed(123)
# fitcontrol<- trainControl(method = "CV", number = 10)
#
# # mod_fitcv<-train(SR ~ H + AGR + NP + DWH  + T + DS, data = lm_DF, na.action = na.omit , method="polr", trControl = fitcontrol)
# mod_fitcv<-train(SR ~ H + AGR + NP, data = lm_DF, na.action = na.omit , method="polr", trControl = fitcontrol)
# # print(mod_fitcv)
# # mod_fitcv<-clm(SR ~ H + AGR + NP + DWH  + T + DS, data = lm_DF, Hess = TRUE)
# summary(mod_fitcv)
#
# ctable <- coef(summary(mod_fitcv))
# p <- pnorm(abs(ctable[, "t value"]), lower.tail = FALSE) * 2
# ctable <- cbind(ctable, "p value" = round(p,4))
# ctable

```


```{r, echo=FALSE}
# pred <- predict(mod_fitcv, lm_DF)
# # pred
# tab<-table(pred, lm_DF$SR)
# tab
# result<- 1- sum(diag(tab))/sum(tab)
# result
```



<!-- \newpage -->
<!-- ## Model with NP3 as reference -->
```{r, echo=FALSE, warning=FALSE}
# lm_DF$NP <- relevel(lm_DF$NP, ref = "3")
# base_model = polr(SR ~ FA + H + NP + AGR + TA + RS + DWH + DS, data = lm_DF, Hess = TRUE)
# summary(base_model)
# ctable <- coef(summary(base_model))
# p <- pnorm(abs(ctable[, "t value"]), lower.tail = FALSE) * 2
# ctable <- cbind(ctable, "p value" = round(p, 4))
# ctable
```


```{r, echo=FALSE, warning=FALSE}
#\newpage
## Model with NP4 as reference and kfold cross validation

# set.seed(123)
# fitcontrol<- trainControl(method = "CV", number = 10, savePredictions = T)
#
# # mod_fitcv<-train(SR ~ H + AGR + NP, data = lm_DF , method="polr", trControl = fitcontrol)
# mod_fitcv<-train(SR ~ H + AGR + NP, data = lm_DF , method="polr", trControl = fitcontrol)
# summary(mod_fitcv)
#
# ctable <- coef(summary(mod_fitcv))
# p <- pnorm(abs(ctable[, "t value"]), lower.tail = FALSE) * 2
# ctable <- cbind(ctable, "p value" = round(p,4))
# ctable

```


<!-- \newpage -->
<!-- ## Model with all variables NP1, DWH2 and DS1 as reference -->
```{r, echo=FALSE, warning=FALSE}

# lm_DF$NP <- relevel(lm_DF$NP, ref = "1")
# lm_DF$DWH <- relevel(lm_DF$DWH, ref = "2")
# 
# mod_fitcv <-
#   polr(SR ~ FA + H + NP + AGR + TA + RS + DWH + DS, data = lm_DF, Hess = TRUE)
# # mod_fitcv<-polr(SR ~ DS, data = lm_DF , Hess = TRUE)
# summary(mod_fitcv)
# 
# ctable <- coef(summary(mod_fitcv))
# p <- pnorm(abs(ctable[, "t value"]), lower.tail = FALSE) * 2
# ctable <- cbind(ctable, "p value" = round(p, 4))
# ctable
```


<!-- \newpage -->
<!-- ## Model with all variables, NP3, DWH1 and DS1 as reference -->
```{r, echo=FALSE, warning=FALSE}

# lm_DF$DS<-relevel(lm_DF$DS, ref = "1")
# lm_DF$NP <- relevel(lm_DF$NP, ref = "3")
# lm_DF$DWH <- relevel(lm_DF$DWH, ref = "1")
# 
# mod_fitcv <-
#   polr(SR ~ FA + H + NP + AGR + TA + RS + DWH + DS, data = lm_DF, Hess = TRUE)
# # mod_fitcv<-polr(SR ~ DS, data = lm_DF , Hess = TRUE)
# summary(mod_fitcv)
# 
# ctable <- coef(summary(mod_fitcv))
# p <- pnorm(abs(ctable[, "t value"]), lower.tail = FALSE) * 2
# ctable <- cbind(ctable, "p value" = round(p, 4))
# ctable
```

<!-- \newpage -->
<!-- ## Model with all variables, NP3, DWH1 and DS1 as reference(New Model) -->
```{r, echo=FALSE, warning=FALSE}

# lm_DF$NP <- relevel(lm_DF$NP, ref = "3")
# lm_DF$DWH <- relevel(lm_DF$DWH, ref = "1")
# 
# mod_fitcv <-
#   polr(SR ~ Rank + NASA + TA + EM + H + NP + FA + DWH + DS + T , data = lm_DF, Hess = TRUE)
# # mod_fitcv<-polr(SR ~ DS, data = lm_DF , Hess = TRUE)
# summary(mod_fitcv)
# 
# ctable <- coef(summary(mod_fitcv))
# p <- pnorm(abs(ctable[, "t value"]), lower.tail = FALSE) * 2
# ctable <- cbind(ctable, "p value" = round(p, 4))
# ctable
```



```{r, echo=FALSE}
file_name = 'ModelData_SR20.csv'
write.csv(lm_DF,
          file.path(curated_data_dir, file_name),
          row.names = FALSE)

```



```{r, echo=FALSE, warning=FALSE}
# \newpage
# ## Model with all variables and Kfold cross validation
# 
# set.seed(123)
# fitcontrol<- trainControl(method = "CV", number = 5, savePredictions = T)
# 
# mod_fitcv2<-train(SR ~ H + AGR + NP + DWH  + DS, data = lm_DF , method="polr", trControl = fitcontrol)
# summary(mod_fitcv2)
# 
# ctable <- coef(summary(mod_fitcv2))
# p <- pnorm(abs(ctable[, "t value"]), lower.tail = FALSE) * 2
# ctable <- cbind(ctable, "p value" = round(p,4))
# ctable

```

```{r, echo=FALSE, warning=FALSE}
# model<-polr(SR ~ H + AGR + NP + DWH  + T + DS, data = lm_DF, Hess = TRUE)
# summary(model)
# ctable <- coef(summary(model))
# p <- pnorm(abs(ctable[, "t value"]), lower.tail = FALSE) * 2
# ctable <- cbind(ctable, "p value" = round(p,4))
# ctable
```


```{r, echo=FALSE}

# \newpage
# ## Cooccurrence matrix and misclassification rate
# pred <- predict(mod_fitcv, lm_DF)
# # pred
# tab<-table(pred, lm_DF$SR)
# tab
# result<- 1- sum(diag(tab))/sum(tab)
# result
```

```{r, echo=FALSE}

## Prediction on testing data
### Cooccurrence matrix and misclassification rate on training data
# pred1 <- predict(mod_fitcv, test_data)
# # pred
# tab1<-table(pred1, test_data$SR)
# tab1
# result<- 1- sum(diag(tab1))/sum(tab1)
# result
```


```{r, echo=FALSE, warning=FALSE}

# lm_DF$NP<-relevel(lm_DF$NP, ref = "4")
# # lm_DF$DS<-relevel(lm_DF$DS, ref = "5")
# # lm_DF$T<-relevel(lm_DF$T, ref = "5")
# 
# set.seed(123)
# fitcontrol<- trainControl(method = "CV", number = 10, savePredictions = T)
# 
# mod_fitcv<-train(SR ~ H + AGR + NP + DWH  + T + DS, data = lm_DF , method="polr", trControl = fitcontrol)
# # summary(mod_fitcv)
# 
# ctable <- coef(summary(mod_fitcv))
# p <- pnorm(abs(ctable[, "t value"]), lower.tail = FALSE) * 2
# ctable <- cbind(ctable, "p value" = round(p,4))
# ctable

```


```{r, echo=FALSE}
# install.packages("randomForest")
# library(randomForest)
# 
# rand_model<- randomForest(SR ~ H + AGR + NP + DWH  + T + DS, data = lm_DF)
# rand_model
# 
# summary(rand_model)
```

```{r, echo=FALSE}

# https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9
# Precision talks about how precise/accurate your model is out of those predicted positive, how many of them are actual positive.
# F1 Score might be a better measure to use if we need to seek a balance between Precision and Recall AND there is an uneven class distribution (large number of Actual Negatives).

# lm_DF$NASA <- as.numeric(lm_DF$NASA)
# lm_DF$TA <- as.numeric(lm_DF$TA)
# lm_DF$AGR <- as.numeric(lm_DF$AGR)

```



<!--```{r}
set.seed(42)
ind <- sample(2, nrow(lm_DF), replace = TRUE, prob = c(0.8, 0.2))
train <- lm_DF[ind==1,]
test <- lm_DF[ind==2,]
```-->


<!-- ## Train Data -->
<!-- ```{r, echo=FALSE} -->
<!-- table(train$SR) -->
<!-- ``` -->
<!-- ## Test Data -->
<!-- ```{r, echo=FALSE} -->
<!-- table(test$SR) -->
<!-- ``` -->



<!-- <!-- ```{r, echo=FALSE} --> -->
<!-- <!-- mylogit <- glm(SR ~ NP + RS + DWH, data = train, family = "binomial") --> -->
<!-- <!-- summary(mylogit) --> -->
<!-- <!-- ``` --> -->

<!-- ```{r, echo=FALSE} -->
<!-- # wald.test(b = coef(mylogit), Sigma = vcov(mylogit), Terms = 4:6) -->
<!-- ``` -->


<!-- \newpage -->
<!-- ## Randomforest base model -->
<!-- ```{r, echo=FALSE} -->
<!-- set.seed(123) -->
<!-- base_model <- randomForest(SR ~ ., data = train, proximity = TRUE, importance=TRUE) -->
<!-- # model <- randomForest(SR ~ ., data = train, proximity = TRUE) -->
<!-- base_model -->
<!-- varImpPlot(base_model) -->
<!-- ``` -->
<!-- <!-- \newpage --> -->
<!-- <!-- ## Importance of features --> -->
<!-- <!-- ```{r, echo=FALSE} --> -->
<!-- <!-- importance(base_model) --> -->
<!-- <!-- ``` --> -->

<!-- \newpage -->
<!-- ## Prediction on test data -->
<!-- ```{r, echo=FALSE} -->
<!-- library(caret) -->
<!-- set.seed(123) -->
<!-- pred_test <- predict(base_model, test) -->
<!-- result <- confusionMatrix(pred_test, test$SR) -->
<!-- result -->
<!-- ``` -->



<!-- \newpage -->
<!-- ## Sensitivity-Specificity-Precision-Recall-F1 -->
<!-- ```{r, echo=FALSE} -->
<!-- result$byClass -->
<!-- rf.roc<-multiclass.roc(train$SR,base_model$votes) -->
<!-- # plot(rf.roc) -->
<!-- # \newline -->
<!-- auc(rf.roc) -->
<!-- ``` -->


<!-- <!-- \newpage --> -->
<!-- <!-- ## Randomforest with impotant features --> -->
<!-- <!-- ```{r, echo=FALSE} --> -->
<!-- <!-- set.seed(123) --> -->
<!-- <!-- model <- randomForest(SR ~ NASA + TA + AV + EM + Task + H + DWH + NP + DWR, data = train, proximity = TRUE) --> -->
<!-- <!-- # model <- randomForest(SR ~ ., data = train, proximity = TRUE) --> -->
<!-- <!-- model --> -->
<!-- <!-- ``` --> -->


<!-- \newpage -->
<!-- ## Randomforest extended model -->
<!-- ```{r, echo=FALSE} -->
<!-- set.seed(123) -->
<!-- model <- randomForest(SR ~ NASA + H + NP + NT + TA + EM + DWH + DS + Rank , data = train, proximity = TRUE, importance=TRUE) -->
<!-- # model <- randomForest(SR ~ ., data = train, proximity = TRUE) -->
<!-- model -->
<!-- varImpPlot(model) -->
<!-- ``` -->


<!-- <!-- \newpage --> -->
<!-- <!-- ## Importance of features --> -->
<!-- <!-- ```{r, echo=FALSE} --> -->
<!-- <!-- importance(model) --> -->
<!-- <!-- ``` --> -->

<!-- \newpage -->
<!-- ## Prediction on test data -->
<!-- ```{r, echo=FALSE} -->
<!-- library(caret) -->
<!-- set.seed(123) -->
<!-- pred_test <- predict(model, test) -->
<!-- result <- confusionMatrix(pred_test, test$SR) -->
<!-- result -->
<!-- ``` -->

<!-- \newpage -->
<!-- ## Sensitivity-Specificity-Precision-Recall-F1 -->
<!-- ```{r, echo=FALSE} -->
<!-- result$byClass -->
<!-- rf.roc<-multiclass.roc(train$SR,model$votes) -->
<!-- auc(rf.roc) -->
<!-- ``` -->





<!-- ```{r} -->
<!-- library(rpart) -->
<!-- library(rpart.plot) -->

<!-- fit <- rpart(SR ~ NP + H + AGR + TA + NASA + DWH + T +DS, data = train, method = 'class') -->
<!-- rpart.plot(fit, extra = 106) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- predict_unseen <-predict(fit, test, type = 'class') -->
<!-- predict_unseen -->
<!-- ``` -->

<!-- ```{r} -->
<!-- table_mat <- table(test$SR, predict_unseen) -->
<!-- table_mat -->
<!-- ``` -->

<!-- ```{r} -->
<!-- accuracy_Test <- sum(diag(table_mat)) / sum(table_mat) -->
<!-- accuracy_Test -->
<!-- print(paste('Accuracy for test', accuracy_Test)) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- library(xgboost) -->
<!-- data(iris) -->
<!-- ``` -->
<!-- ```{r} -->
<!-- species = iris$Species -->
<!-- label = as.integer(iris$Species)-1 -->
<!-- iris$Species = NULL -->
<!-- ``` -->

<!-- ```{r} -->
<!-- n = nrow(iris) -->
<!-- train.index = sample(n,floor(0.75*n)) -->
<!-- train.data = as.matrix(iris[train.index,]) -->
<!-- train.label = label[train.index] -->
<!-- test.data = as.matrix(iris[-train.index,]) -->
<!-- test.label = label[-train.index] -->
<!-- ``` -->

<!-- ```{r} -->
<!-- xgb.train = xgb.DMatrix(data=train.data,label=train.label) -->
<!-- xgb.test = xgb.DMatrix(data=test.data,label=test.label) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- num_class = length(levels(species)) -->
<!-- params = list( -->
<!--   booster="gbtree", -->
<!--   eta=0.001, -->
<!--   max_depth=5, -->
<!--   gamma=3, -->
<!--   subsample=0.75, -->
<!--   colsample_bytree=1, -->
<!--   objective="multi:softprob", -->
<!--   eval_metric="mlogloss", -->
<!--   num_class=num_class -->
<!-- ) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- # Train the XGBoost classifer -->
<!-- xgb.fit=xgb.train( -->
<!--   params=params, -->
<!--   data=xgb.train, -->
<!--   nrounds=10000, -->
<!--   nthreads=1, -->
<!--   early_stopping_rounds=10, -->
<!--   watchlist=list(val1=xgb.train,val2=xgb.test), -->
<!--   verbose=0 -->
<!-- ) -->

<!-- # Review the final model and results -->
<!-- xgb.fit -->
<!-- ``` -->
<!-- ```{r} -->
<!-- # Predict outcomes with the test data -->
<!-- xgb.pred = predict(xgb.fit,test.data,reshape=T) -->
<!-- xgb.pred = as.data.frame(xgb.pred) -->
<!-- colnames(xgb.pred) = levels(species) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- # Use the predicted label with the highest probability -->
<!-- xgb.pred$prediction = apply(xgb.pred,1,function(x) colnames(xgb.pred)[which.max(x)]) -->
<!-- xgb.pred$label = levels(species)[test.label+1] -->
<!-- ``` -->

<!-- ```{r} -->
<!-- # Calculate the final accuracy -->
<!-- result = sum(xgb.pred$prediction==xgb.pred$label)/nrow(xgb.pred) -->
<!-- print(paste("Final Accuracy =",sprintf("%1.2f%%", 100*result))) -->
<!-- ``` -->

